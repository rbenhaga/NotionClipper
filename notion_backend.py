#!/usr/bin/env python3
"""
Backend API pour Notion Clipper Pro - Version 100% Locale Optimis√©e
Sans webhooks externes, avec polling intelligent et cache avanc√©
"""

import os
import sys
import io
import json
import time
import base64
import hashlib
import threading
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any, Set
from dataclasses import dataclass, asdict
from collections import OrderedDict
import gzip
import pickle
from queue import Queue
from pathlib import Path
import re
from PIL import ImageGrab
from io import BytesIO
from collections.abc import Mapping
from types import MappingProxyType

from flask import Flask, request, jsonify, Response, current_app
from flask_cors import CORS
from notion_client import Client
from dotenv import load_dotenv
import requests
from PIL import Image
import pyperclip
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC

try:
    from backend.config import SecureConfig, MAX_CLIPBOARD_LENGTH, CACHE_DURATION, SMART_POLL_INTERVAL
    from backend.cache import NotionCache
    from backend.utils import get_clipboard_content, detect_content_type
except ImportError:
    print("‚ö†Ô∏è Modules backend non trouv√©s, utilisation du code int√©gr√©")
    # Inclure le code directement ici temporairement

# Configuration
load_dotenv()
app = Flask(__name__)
CORS(app)

# Constants et variables globales
secure_config = SecureConfig()
APP_DIR = secure_config.app_dir
CACHE_FILE = APP_DIR / "notion_cache.json"
DELTA_FILE = APP_DIR / "notion_delta.json"
PREFERENCES_FILE = APP_DIR / "notion_preferences.json"
CONFIG_FILE = APP_DIR / "notion_config.json"
ONBOARDING_FILE = APP_DIR / "notion_onboarding.json"
MAX_PAGES_PER_REQUEST = 100

notion = None
notion_token = None
imgbb_key = None
last_check_time = 0
changes_queue = Queue()
polling_thread = None

# Stats pour optimisation
stats = {
    "api_calls": 0,
    "cache_hits": 0,
    "cache_misses": 0,
    "last_full_sync": None,
    "changes_detected": 0,
    "first_run": True
}

# Utilisation du cache refactoris√©
smart_cache = NotionCache(APP_DIR)

# Variables globales pour le suivi des changements
last_check_timestamp = None
pages_snapshot = {}
update_history = []

# Ajout utilitaires cache si non import√©s (doit √™tre d√©fini AVANT toute utilisation)
def load_cache():
    try:
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception:
        return {}
def save_cache(data):
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

class SmartPoller:
    """Polling intelligent qui d√©tecte les changements."""
    
    def __init__(self):
        self.running = False
        self.last_full_sync = 0
        self.quick_check_interval = 30  # 30 secondes pour check rapide
        self.full_sync_interval = 300  # 5 minutes pour sync compl√®te
    
    def start(self):
        """D√©marre le polling intelligent."""
        if self.running:
            return
        
        self.running = True
        self.thread = threading.Thread(target=self._poll_loop, daemon=True)
        self.thread.start()
        print("‚úÖ Smart Polling d√©marr√©")
    
    def stop(self):
        """Arr√™te le polling."""
        self.running = False
    
    def _poll_loop(self):
        """Boucle de polling intelligente."""
        while self.running:
            try:
                current_time = time.time()
                
                # Check rapide : uniquement la premi√®re page pour voir s'il y a des changements
                if self._quick_check():
                    # Des changements d√©tect√©s, faire une sync plus compl√®te
                    self._incremental_sync()
                
                # Sync compl√®te p√©riodique
                if current_time - self.last_full_sync > self.full_sync_interval:
                    self._full_sync()
                    self.last_full_sync = current_time
                
                # Attendre avant le prochain check
                time.sleep(self.quick_check_interval)
                
            except Exception as e:
                print(f"‚ùå Erreur polling: {e}")
                time.sleep(60)  # Attendre 1 minute en cas d'erreur
    
    def _quick_check(self) -> bool:
        """Check rapide pour d√©tecter s'il y a eu des changements."""
        if not notion:
            return False
        
        try:
            stats["api_calls"] += 1
            
            # R√©cup√©rer juste la page la plus r√©cemment modifi√©e
            response = notion.search(
                filter={"property": "object", "value": "page"},
                page_size=1,
                sort={
                    "timestamp": "last_edited_time",
                    "direction": "descending"
                }
            )
            
            if response.get("results"):  # type: ignore
                latest_page = response["results"][0]  # type: ignore
                latest_time = latest_page.get("last_edited_time", "")  # type: ignore
                
                # Comparer avec le dernier temps connu
                cached_pages = smart_cache.get_all_pages()
                if cached_pages:
                    cached_latest = max(cached_pages, key=lambda p: p.get("last_edited", ""))
                    cached_time = cached_latest.get("last_edited", "")
                    
                    if latest_time != cached_time:
                        stats["changes_detected"] += 1
                        return True
            
            return False
            
        except Exception as e:
            print(f"Erreur quick check: {e}")
            return False
    
    def _incremental_sync(self):
        """Synchronisation incr√©mentale des changements r√©cents."""
        if not notion:
            return
        
        try:
            print("üîÑ Sync incr√©mentale...")
            changes_count = 0
            
            # R√©cup√©rer les 50 derni√®res pages modifi√©es
            stats["api_calls"] += 1
            response = notion.search(
                filter={"property": "object", "value": "page"},
                page_size=50,
                sort={
                    "timestamp": "last_edited_time",
                    "direction": "descending"
                }
            )
            
            for page_data in response.get("results", []):  # type: ignore
                processed = process_page_data(page_data)
                if smart_cache.update_page(processed):
                    changes_count += 1
                    # Notifier le changement
                    changes_queue.put({
                        "type": "page_updated",
                        "page": processed,
                        "timestamp": time.time()
                    })
            
            if changes_count > 0:
                smart_cache.save_to_disk()
                print(f"‚úÖ {changes_count} pages mises √† jour")
                
        except Exception as e:
            print(f"‚ùå Erreur sync incr√©mentale: {e}")
    
    def _full_sync(self):
        """Synchronisation compl√®te de toutes les pages."""
        if not notion:
            return
        
        try:
            print("üîÑ Sync compl√®te...")
            all_pages = []
            cursor = None
            has_more = True
            
            while has_more and len(all_pages) < 2000:  # Limite de s√©curit√©
                stats["api_calls"] += 1
                
                params = {
                    "filter": {"property": "object", "value": "page"},
                    "page_size": MAX_PAGES_PER_REQUEST,
                    "sort": {
                        "timestamp": "last_edited_time",
                        "direction": "descending"
                    }
                }
                if cursor:
                    params["start_cursor"] = cursor
                
                response = notion.search(**params)
                
                for page_data in response.get("results", []):  # type: ignore
                    processed = process_page_data(page_data)
                    all_pages.append(processed)
                    smart_cache.update_page(processed)
                
                has_more = response.get("has_more", False)  # type: ignore
                cursor = response.get("next_cursor")  # type: ignore
                
                # Pause pour respecter rate limit
                time.sleep(0.3)
            
            smart_cache.save_to_disk()
            stats["last_full_sync"] = datetime.now().isoformat()
            print(f"‚úÖ Sync compl√®te: {len(all_pages)} pages")
            
        except Exception as e:
            print(f"‚ùå Erreur sync compl√®te: {e}")

# Instance globale du poller
smart_poller = SmartPoller()

def process_page_data(page_data: Dict) -> Dict:
    """Traite les donn√©es d'une page Notion."""
    return {
        "id": page_data["id"],
        "title": extract_title(page_data),
        "icon": extract_icon(page_data),
        "parent_type": page_data.get("parent", {}).get("type", "page"),
        "url": page_data.get("url"),
        "last_edited": page_data.get("last_edited_time"),
        "created_time": page_data.get("created_time")
    }

def extract_title(page_data: Dict) -> str:
    """Extrait le titre d'une page."""
    try:
        if "properties" in page_data:
            for prop_name, prop_data in page_data["properties"].items():
                if prop_data.get("type") == "title" and prop_data.get("title"):
                    return "".join([
                        text_obj.get("plain_text", "") 
                        for text_obj in prop_data["title"]
                    ]).strip() or "Page sans titre"
    except:
        pass
    return "Page sans titre"

def extract_icon(page_data: Dict) -> Optional[Any]:
    """Extrait l'ic√¥ne d'une page."""
    try:
        icon = page_data.get("icon")
        if not icon:
            return None
            
        if icon["type"] == "emoji":
            return {"type": "emoji", "emoji": icon["emoji"]}
        elif icon["type"] == "external":
            return {"type": "external", "external": {"url": icon["external"]["url"]}}
        elif icon["type"] == "file":
            return {"type": "file", "file": {"url": icon["file"]["url"]}}
    except:
        pass
    return None

def load_configuration():
    """Charge la configuration depuis le stockage s√©curis√©."""
    global notion, notion_token, imgbb_key
    config = secure_config.load_config()
    notion_token = config.get('notionToken') or os.getenv('NOTION_TOKEN')
    imgbb_key = config.get('imgbbKey') or os.getenv('IMGBB_API_KEY')
    if notion_token:
        notion = Client(auth=notion_token)
        print(f"‚úÖ Client Notion configur√©")
        print(f"  Token: {notion_token[:10]}...")
        
        # D√©marrer le polling intelligent
        smart_poller.start()

# Routes API

@app.route('/api/health')
def health_check():
    """Health check avec stats."""
    cache_pages = smart_cache.get_all_pages()
    
    return jsonify({
        "status": "healthy",
        "timestamp": time.time(),
        "notion_connected": notion is not None,
        "imgbb_configured": imgbb_key is not None,
        "cache_stats": {
            "total_pages": len(cache_pages),
            "api_calls": stats["api_calls"],
            "cache_hits": stats["cache_hits"],
            "cache_misses": stats["cache_misses"],
            "changes_detected": stats["changes_detected"],
            "last_full_sync": stats["last_full_sync"]
        },
        "polling_active": smart_poller.running
    })

@app.route('/api/pages')
def get_pages():
    """R√©cup√®re les pages depuis le cache intelligent."""
    try:
        force_refresh = request.args.get('force_refresh', 'false').lower() == 'true'
        
        if force_refresh:
            # Forcer une sync incr√©mentale
            smart_poller._incremental_sync()
        
        # Toujours servir depuis le cache
        pages = smart_cache.get_all_pages()
        stats["cache_hits"] += 1
        
        # Trier par date de modification
        pages.sort(key=lambda x: x.get("last_edited", ""), reverse=True)
        
        return jsonify({
            "pages": pages,
            "cached": True,
            "timestamp": time.time(),
            "count": len(pages),
            "from_cache": True,
            "stats": {
                "api_calls_saved": stats["cache_hits"],
                "changes_detected": stats["changes_detected"]
            }
        })
        
    except Exception as e:
        print(f"‚ùå Erreur get_pages: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/pages/changes')
def get_changes():
    """R√©cup√®re les changements depuis un timestamp."""
    try:
        since = request.args.get('since', '0')
        timestamp = float(since)
        
        changes = smart_cache.get_changes_since(timestamp)
        
        return jsonify({
            "changes": changes,
            "count": len(changes),
            "timestamp": time.time()
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/events/stream')
def event_stream():
    """Server-Sent Events pour les changements en temps r√©el."""
    def generate():
        # Envoyer un ping initial
        yield f"data: {json.dumps({'type': 'connected', 'timestamp': time.time()})}\n\n"
        
        while True:
            try:
                # Attendre un changement (timeout de 30s pour garder la connexion alive)
                try:
                    change = changes_queue.get(timeout=30)
                    yield f"data: {json.dumps(change)}\n\n"
                except:
                    # Timeout, envoyer un ping
                    yield f"data: {json.dumps({'type': 'ping', 'timestamp': time.time()})}\n\n"
                    
            except GeneratorExit:
                break
            except Exception as e:
                print(f"SSE error: {e}")
                break
    
    return Response(generate(), mimetype='text/event-stream')

@app.route('/api/config', methods=['POST'])
def update_config():
    """Met √† jour la configuration de mani√®re s√©curis√©e."""
    try:
        data = request.get_json()
        secure_config.save_config({
            "notionToken": data.get("notionToken", ""),
            "imgbbKey": data.get("imgbbKey", "")
        })
        load_configuration()
        
        # V√©rifier si Notion est bien connect√©
        notion_connected = False
        error_message = None
        
        if notion:
            try:
                # Test de connexion avec l'API Notion
                test_response = notion.users.me()
                notion_connected = True
                user_name = getattr(test_response, 'get', lambda x, d=None: None)('name', 'Unknown')
                print(f"Connexion Notion OK - User: {user_name}")
            except Exception as e:
                error_message = str(e)
                print(f"Erreur test Notion: {error_message}")
                notion_connected = False
        else:
            error_message = "Client Notion non initialis√©"
        
        if notion_connected:
            # Si connect√©, lancer une sync en arri√®re-plan
            if notion:
                threading.Thread(target=fetch_all_pages, daemon=True).start()
            
            return jsonify({
                "success": True,
                "message": "Configuration mise √† jour avec succ√®s",
                "notion_connected": True
            })
        else:
            # Si erreur, retourner les d√©tails
            return jsonify({
                "success": False,
                "message": f"Erreur de connexion Notion: {error_message}",
                "notion_connected": False,
                "error": error_message
            }), 400
        
    except Exception as e:
        print(f"Erreur config: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e),
            "message": f"Erreur serveur: {str(e)}"
        }), 500

@app.route('/api/clipboard')
def get_clipboard():
    """R√©cup√®re le contenu du presse-papiers avec support √©tendu."""
    try:
        content = get_clipboard_content()
        return jsonify(content)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/send', methods=['POST'])
def send_to_notion():
    """Envoie le contenu vers une page."""
    try:
        data = request.get_json()
        page_id = data.get('page_id')
        content = data.get('content')
        content_type = data.get('content_type', 'text')
        is_image = data.get('is_image', False)
        
        if not page_id or not content:
            return jsonify({"error": "page_id et content requis"}), 400
        
        if not notion:
            return jsonify({"error": "Notion non configur√©"}), 400
        
        stats["api_calls"] += 1
        
        # Cr√©er le bloc
        if is_image and content_type == 'image':
            # Upload image si configur√©
            image_url = upload_image_to_imgbb(content) if imgbb_key else None
            
            if image_url:
                block = {
                    "object": "block",
                    "type": "image",
                    "image": {
                        "type": "external",
                        "external": {"url": image_url}
                    }
                }
            else:
                block = {
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [{
                            "type": "text",
                            "text": {"content": f"[Image - {datetime.now().strftime('%d/%m/%Y %H:%M')}]"}
                        }]
                    }
                }
        else:
            block = {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{
                        "type": "text",
                        "text": {"content": content}
                    }]
                }
            }
        
        # Envoyer √† Notion
        notion.blocks.children.append(block_id=page_id, children=[block])
        
        # Invalider le cache pour cette page (forcer une mise √† jour au prochain check)
        changes_queue.put({
            "type": "content_sent",
            "page_id": page_id,
            "timestamp": time.time()
        })
        
        return jsonify({
            "success": True,
            "message": "Contenu envoy√©"
        })
        
    except Exception as e:
        print(f"‚ùå Erreur envoi: {e}")
        return jsonify({"error": str(e)}), 500

def create_block_content(content, block_type, tags=None, source_url=None):
    """Cr√©e dynamiquement un bloc Notion selon le type et les propri√©t√©s."""
    tags = tags or []
    rich_text = [{"type": "text", "text": {"content": content}}]
    if tags:
        rich_text.append({"type": "text", "text": {"content": f"  #" + " #".join(tags)}})
    if source_url:
        rich_text.append({"type": "text", "text": {"content": f"\nüîó {source_url}"}})
    if block_type == "heading_1":
        return {"object": "block", "type": "heading_1", "heading_1": {"rich_text": rich_text}}
    elif block_type == "heading_2":
        return {"object": "block", "type": "heading_2", "heading_2": {"rich_text": rich_text}}
    elif block_type == "bulleted_list":
        return {"object": "block", "type": "bulleted_list_item", "bulleted_list_item": {"rich_text": rich_text}}
    elif block_type == "numbered_list":
        return {"object": "block", "type": "numbered_list_item", "numbered_list_item": {"rich_text": rich_text}}
    elif block_type == "toggle":
        return {"object": "block", "type": "toggle", "toggle": {"rich_text": rich_text}}
    elif block_type == "quote":
        return {"object": "block", "type": "quote", "quote": {"rich_text": rich_text}}
    elif block_type == "callout":
        return {"object": "block", "type": "callout", "callout": {"rich_text": rich_text, "icon": {"emoji": "üí°"}}}
    elif block_type == "code":
        return {"object": "block", "type": "code", "code": {"rich_text": rich_text, "language": "plain text"}}
    else:
        return {"object": "block", "type": "paragraph", "paragraph": {"rich_text": rich_text}}

def add_favorite_marker(block):
    """Ajoute un emoji favori au bloc (ex: ‚≠ê)."""
    if "callout" in block:
        block["callout"]["icon"] = {"emoji": "‚≠ê"}
    elif "paragraph" in block:
        if "rich_text" in block["paragraph"]:
            block["paragraph"]["rich_text"].insert(0, {"type": "text", "text": {"content": "‚≠ê "}})
    elif "heading_1" in block:
        block["heading_1"]["rich_text"].insert(0, {"type": "text", "text": {"content": "‚≠ê "}})
    elif "heading_2" in block:
        block["heading_2"]["rich_text"].insert(0, {"type": "text", "text": {"content": "‚≠ê "}})
    return block

@app.route('/api/send_multiple', methods=['POST'])
def send_to_multiple_pages():
    """Envoie vers plusieurs pages avec propri√©t√©s enrichies."""
    try:
        data = request.get_json()
        page_ids = data.get('page_ids', [])
        content = data.get('content', '')
        content_type = data.get('content_type', 'text')
        block_type = data.get('block_type', 'paragraph')
        properties = data.get('properties', {})
        if not page_ids or not content:
            return jsonify({"error": "page_ids et content requis"}), 400
        if not notion:
            return jsonify({"error": "Notion non configur√©"}), 400
        success_count = 0
        errors = []
        for page_id in page_ids:
            try:
                blocks = []
                if content_type == 'video':
                    video_url = data.get('video_url', content)
                    blocks.append(create_video_block(video_url))
                elif content_type == 'image':
                    image_data = data.get('image_data', content)
                    blocks.append(create_image_block(image_data))
                elif content_type == 'table':
                    blocks.extend(create_table_block(content))
                elif content_type == 'markdown' or data.get('isMarkdown'):
                    blocks.extend(parse_markdown_to_blocks(content))
                else:
                    block = create_block_content(
                        content, 
                        block_type,
                        properties.get('tags', []),
                        properties.get('source_url')
                    )
                    if properties.get('is_favorite'):
                        block = add_favorite_marker(block)
                    blocks.append(block)
                if any([properties.get('category'), properties.get('due_date'), properties.get('source_url')]):
                    metadata_parts = []
                    if properties.get('category'):
                        metadata_parts.append(f"üìÅ {properties['category']}")
                    if properties.get('due_date'):
                        metadata_parts.append(f"üìÖ {properties['due_date']}")
                    if properties.get('source_url'):
                        metadata_parts.append(f"üîó {properties['source_url']}")
                    if metadata_parts:
                        blocks.append({
                            "object": "block",
                            "type": "callout",
                            "callout": {
                                "rich_text": [{"type": "text", "text": {"content": " ‚Ä¢ ".join(metadata_parts)}}],
                                "icon": {"emoji": "‚ÑπÔ∏è"},
                                "color": "gray_background"
                            }
                        })
                if properties.get('has_reminder'):
                    blocks.append({
                        "object": "block",
                        "type": "to_do",
                        "to_do": {
                            "rich_text": [{"type": "text", "text": {"content": "üîî Rappel activ√© pour ce contenu"}}],
                            "checked": False
                        }
                    })
                notion.blocks.children.append(block_id=page_id, children=blocks)
                success_count += 1
                changes_queue.put({
                    "type": "content_sent",
                    "page_id": page_id,
                    "timestamp": time.time()
                })
            except Exception as e:
                print(f"‚ùå Erreur envoi vers {page_id}: {e}")
                errors.append({"page_id": page_id, "error": str(e)})
        return jsonify({
            "success": True,
            "success_count": success_count,
            "total": len(page_ids),
            "errors": errors,
            "message": f"Contenu envoy√© vers {success_count}/{len(page_ids)} pages"
        })
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale: {e}")
        return jsonify({"error": str(e)}), 500

def upload_image_to_imgbb(base64_image):
    """Upload une image vers ImgBB avec gestion d'erreur am√©lior√©e."""
    if not imgbb_key:
        print("‚ö†Ô∏è Cl√© ImgBB non configur√©e")
        return None
    try:
        if ',' in base64_image:
            base64_image = base64_image.split(',')[1]
        response = requests.post(
            "https://api.imgbb.com/1/upload",
            data={
                'key': imgbb_key,
                'image': base64_image,
                'expiration': 15552000
            },
            timeout=30
        )
        if response.status_code == 200:
            data = response.json()
            if data['success']:
                image_url = data['data']['url']
                print(f"‚úÖ Image upload√©e: {image_url}")
                cache_data = load_cache() if 'load_cache' in globals() else {}
                if 'uploaded_images' not in cache_data:
                    cache_data['uploaded_images'] = []
                cache_data['uploaded_images'].append({
                    'url': image_url,
                    'timestamp': time.time(),
                    'delete_url': data['data'].get('delete_url')
                })
                if 'save_cache' in globals():
                    save_cache(cache_data)
                return image_url
        print(f"‚ùå Erreur ImgBB: {response.text}")
        return None
    except Exception as e:
        print(f"‚ùå Erreur upload image: {e}")
        return None

def fetch_all_pages():
    try:
        smart_poller._full_sync()
    except Exception as e:
        print(f"Erreur lors de la synchronisation compl√®te: {e}")

def check_first_run():
    """V√©rifie si c'est la premi√®re utilisation."""
    if os.path.exists(ONBOARDING_FILE):
        try:
            with open(ONBOARDING_FILE, 'r') as f:
                data = json.load(f)
                return data.get("completed", False)
        except:
            pass
    return False

@app.route('/api/onboarding/complete', methods=['POST'])
def complete_onboarding():
    """Marque l'onboarding comme compl√©t√©."""
    try:
        # Cr√©er le fichier de marqueur
        onboarding_data = {
            "completed": True,
            "timestamp": time.time(),
            "date": datetime.now().isoformat()
        }
        
        # Utiliser le bon chemin selon l'OS
        if hasattr(sys, '_MEIPASS'):
            # App packag√©e
            base_path = os.path.dirname(sys.executable)
        else:
            # D√©veloppement
            base_path = os.path.dirname(os.path.abspath(__file__))
        
        onboarding_file = os.path.join(base_path, ONBOARDING_FILE)
        
        with open(onboarding_file, 'w', encoding='utf-8') as f:
            json.dump(onboarding_data, f, ensure_ascii=False, indent=2)
        
        # Mettre √† jour les stats
        stats["first_run"] = False
        
        print("Onboarding marqu√© comme compl√©t√©")
        
        return jsonify({
            "success": True,
            "message": "Onboarding compl√©t√©"
        })
        
    except Exception as e:
        print(f"Erreur onboarding complete: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/clear_cache', methods=['POST'])
def clear_cache():
    """Vide le cache multi-niveaux."""
    try:
        # Vider le cache m√©moire
        if 'smart_cache' in globals():
            smart_cache.pages_cache.clear()
            smart_cache.page_hashes.clear()
            smart_cache.last_modified.clear()
        # Supprimer les fichiers cache
        for cache_file in [CACHE_FILE, DELTA_FILE]:
            if os.path.exists(cache_file):
                os.remove(cache_file)
        # R√©initialiser les stats
        stats["cache_hits"] = 0
        stats["cache_misses"] = 0
        stats["last_full_sync"] = None
        return jsonify({
            "success": True,
            "message": "Cache vid√© avec succ√®s"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/cleanup_images', methods=['POST'])
def cleanup_uploaded_images():
    """Nettoie les anciennes images upload√©es."""
    try:
        cache_data = load_cache() if 'load_cache' in globals() else {}
        images = cache_data.get('uploaded_images', [])
        cutoff_time = time.time() - (30 * 24 * 60 * 60)
        kept_images = []
        deleted_count = 0
        for img in images:
            if img['timestamp'] < cutoff_time and img.get('delete_url'):
                try:
                    requests.get(img['delete_url'])
                    deleted_count += 1
                except:
                    pass
            else:
                kept_images.append(img)
        cache_data['uploaded_images'] = kept_images
        if 'save_cache' in globals():
            save_cache(cache_data)
        return jsonify({
            "success": True,
            "deleted": deleted_count,
            "remaining": len(kept_images)
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/pages/<page_id>/database', methods=['GET'])
def check_if_database(page_id):
    """V√©rifie si une page est une base de donn√©es."""
    try:
        if not notion:
            return jsonify({"is_database": False})
        db = notion.databases.retrieve(database_id=page_id)
        # Force conversion en dict si besoin
        if not isinstance(db, dict):
            db = json.loads(json.dumps(db))
        return jsonify({
            "is_database": True,
            "properties": db.get('properties', {}),
            "title": db.get('title', [{}])[0].get('plain_text', 'Base de donn√©es')
        })
    except Exception:
        return jsonify({"is_database": False})

@app.route('/api/database/<db_id>/create_page', methods=['POST'])
def create_database_page(db_id):
    """Cr√©e une nouvelle entr√©e dans une base de donn√©es."""
    try:
        if not notion:
            return jsonify({"error": "Notion non configur√©"}), 400
        data = request.get_json()
        properties = {
            "Name": {
                "title": [{
                    "text": {
                        "content": data.get('title', 'Nouveau clip')
                    }
                }]
            }
        }
        if data.get('properties'):
            for prop_name, prop_value in data['properties'].items():
                if prop_name == 'Tags' and isinstance(prop_value, list):
                    properties[prop_name] = {
                        "multi_select": [{"name": tag} for tag in prop_value]
                    }
                elif prop_name == 'URL' and prop_value:
                    properties[prop_name] = {"url": prop_value}  # type: ignore
                elif prop_name == 'Date' and prop_value:
                    properties[prop_name] = {"date": {"start": prop_value}}  # type: ignore
                elif prop_name == 'Category' and prop_value:
                    properties[prop_name] = {"select": {"name": prop_value}}  # type: ignore
        new_page = notion.pages.create(
            parent={"database_id": db_id},
            properties=properties,
            children=data.get('blocks', [])
        )
        # Force conversion en dict si besoin
        if not isinstance(new_page, dict):
            new_page = json.loads(json.dumps(new_page))
        page_id = new_page.get('id')
        url = new_page.get('url')
        return jsonify({
            "success": True,
            "page_id": page_id,
            "url": url
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

def get_clipboard_content():
    """R√©cup√®re et analyse le contenu du presse-papiers avec d√©tection am√©lior√©e."""
    try:
        # Tentative de r√©cup√©ration d'image
        image_clip = ImageGrab.grabclipboard()
        # Sur certains OS, grabclipboard() peut retourner une liste de chemins
        if isinstance(image_clip, list) and image_clip and isinstance(image_clip[0], str):
            for path in image_clip:
                try:
                    with Image.open(path) as image:
                        if hasattr(image, 'save'):
                            buffered = BytesIO()
                            image.save(buffered, format="PNG")
                            img_str = base64.b64encode(buffered.getvalue()).decode()
                            return {
                                "type": "image",
                                "content": f"data:image/png;base64,{img_str}",
                                "imageData": f"data:image/png;base64,{img_str}",
                                "originalFormat": "png",
                                "size": len(img_str)
                            }
                except Exception:
                    continue
        elif image_clip is not None and hasattr(image_clip, 'save'):
            buffered = BytesIO()
            image_clip.save(buffered, format="PNG")  # type: ignore
            img_str = base64.b64encode(buffered.getvalue()).decode()
            return {
                "type": "image",
                "content": f"data:image/png;base64,{img_str}",
                "imageData": f"data:image/png;base64,{img_str}",
                "originalFormat": "png",
                "size": len(img_str)
            }
        # Si c'est une liste mais pas des chemins d'image, ignorer
    except Exception:
        pass
    
    # R√©cup√©ration du texte
    text = pyperclip.paste()
    if text:
        # D√©tection YouTube
        youtube_match = re.search(r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([\w-]+)', text)
        if youtube_match:
            video_id = youtube_match.group(1)
            return {
                "type": "video",
                "content": text,
                "videoUrl": f"https://www.youtube.com/watch?v={video_id}",
                "videoId": video_id,
                "platform": "youtube"
            }
        
        # D√©tection URL d'image
        if re.match(r'^https?://.*\.(jpg|jpeg|png|gif|webp)', text, re.IGNORECASE):
            return {
                "type": "image",
                "content": text,
                "imageUrl": text,
                "isExternal": True
            }
        
        # D√©tection Markdown
        markdown_patterns = [
            r'^#{1,6}\s',  # Headers
            r'^\*\s',       # Bullet lists
            r'^\d+\.\s',    # Numbered lists
            r'^```',        # Code blocks
            r'^\>',         # Quotes
            r'\[.+\]\(.+\)' # Links
        ]
        
        is_markdown = any(re.search(pattern, text, re.MULTILINE) for pattern in markdown_patterns)
        
        # D√©tection tableau
        if '\t' in text and '\n' in text:
            lines = text.strip().split('\n')
            if len(lines) > 1:
                first_row_tabs = lines[0].count('\t')
                if all(line.count('\t') == first_row_tabs for line in lines[1:]):
                    return {
                        "type": "table",
                        "content": text,
                        "rows": len(lines),
                        "columns": first_row_tabs + 1
                    }
        
        # Texte normal ou Markdown
        return {
            "type": "text",
            "content": text[:MAX_CLIPBOARD_LENGTH],
            "truncated": len(text) > MAX_CLIPBOARD_LENGTH,
            "originalLength": len(text),
            "isMarkdown": is_markdown
        }
    
    return None

def create_video_block(url, video_id=None):
    """Cr√©e un bloc vid√©o Notion."""
    if 'youtube' in url or 'youtu.be' in url:
        return {
            "object": "block",
            "type": "video",
            "video": {
                "type": "external",
                "external": {"url": url}
            }
        }
    return create_block_content(f"üé• Vid√©o: {url}", "paragraph")

def create_image_block(image_data_or_url):
    """Cr√©e un bloc image Notion."""
    if image_data_or_url.startswith('data:image/'):
        image_url = upload_image_to_imgbb(image_data_or_url) if imgbb_key else None
        if image_url:
            return {
                "object": "block",
                "type": "image",
                "image": {
                    "type": "external",
                    "external": {"url": image_url}
                }
            }
    elif image_data_or_url.startswith('http'):
        return {
            "object": "block",
            "type": "image",
            "image": {
                "type": "external",
                "external": {"url": image_data_or_url}
            }
        }
    return create_block_content("[Image non disponible]", "paragraph")

def parse_markdown_to_blocks(markdown_text):
    """Convertit du Markdown en blocs Notion."""
    blocks = []
    lines = markdown_text.split('\n')
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        if line.startswith('#'):
            level = len(line.split()[0])
            text = line[level:].strip()
            block_type = f"heading_{min(level, 3)}"
            blocks.append({
                "object": "block",
                "type": block_type,
                block_type: {
                    "rich_text": [{"type": "text", "text": {"content": text}}]
                }
            })
        elif line.startswith('```'):
            code_lines = []
            language = line[3:].strip() or "plain text"
            i += 1
            while i < len(lines) and not lines[i].strip().startswith('```'):
                code_lines.append(lines[i])
                i += 1
            blocks.append({
                "object": "block",
                "type": "code",
                "code": {
                    "rich_text": [{"type": "text", "text": {"content": '\n'.join(code_lines)}}],
                    "language": language
                }
            })
        elif line.startswith('* ') or line.startswith('- '):
            blocks.append({
                "object": "block",
                "type": "bulleted_list_item",
                "bulleted_list_item": {
                    "rich_text": [{"type": "text", "text": {"content": line[2:]}}]
                }
            })
        elif re.match(r'^\d+\.\s', line):
            text = re.sub(r'^\d+\.\s', '', line)
            blocks.append({
                "object": "block",
                "type": "numbered_list_item",
                "numbered_list_item": {
                    "rich_text": [{"type": "text", "text": {"content": text}}]
                }
            })
        elif line.startswith('>'):
            blocks.append({
                "object": "block",
                "type": "quote",
                "quote": {
                    "rich_text": [{"type": "text", "text": {"content": line[1:].strip()}}]
                }
            })
        elif line:
            blocks.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": line}}]
                }
            })
        i += 1
    return blocks if blocks else [create_block_content(markdown_text, "paragraph")]

def create_table_block(table_content):
    """Cr√©e un bloc table Notion √† partir de donn√©es tabulaires."""
    rows = table_content.strip().split('\n')
    if not rows:
        return [create_block_content(table_content, "paragraph")]
    blocks = []
    headers = rows[0].split('\t')
    blocks.append({
        "object": "block",
        "type": "callout",
        "callout": {
            "rich_text": [{"type": "text", "text": {"content": " | ".join(headers)}}],
            "icon": {"emoji": "üìä"}
        }
    })
    for row in rows[1:]:
        cells = row.split('\t')
        blocks.append({
            "object": "block",
            "type": "bulleted_list_item",
            "bulleted_list_item": {
                "rich_text": [{"type": "text", "text": {"content": " | ".join(cells)}}]
            }
        })
    return blocks

@app.route('/api/pages/check_updates')
def check_updates():
    """V√©rifie s'il y a eu des mises √† jour de pages Notion depuis la derni√®re v√©rification."""
    global last_check_timestamp, pages_snapshot
    try:
        has_updates = False
        updated_pages = []
        new_pages = []
        deleted_pages = []
        # R√©cup√©rer l'√©tat actuel depuis le cache
        cache_data = load_cache()
        current_pages = cache_data.get('pages', [])
        # Si c'est la premi√®re v√©rification
        if not pages_snapshot:
            pages_snapshot = {page['id']: {
                'last_edited': page.get('last_edited_time'),
                'title': page.get('title'),
                'hash': _generate_page_hash(page)
            } for page in current_pages}
            last_check_timestamp = time.time()
            return jsonify({
                "has_updates": False,
                "first_check": True,
                "total_pages": len(current_pages)
            })
        # Cr√©er un dictionnaire des pages actuelles pour comparaison rapide
        current_pages_dict = {page['id']: page for page in current_pages}
        # 1. V√©rifier les pages modifi√©es ou nouvelles
        for page in current_pages:
            page_id = page['id']
            current_hash = _generate_page_hash(page)
            if page_id not in pages_snapshot:
                # Nouvelle page
                new_pages.append({
                    'id': page_id,
                    'title': page.get('title', 'Sans titre'),
                    'url': page.get('url'),
                    'icon': page.get('icon')
                })
                has_updates = True
            else:
                # V√©rifier si la page a √©t√© modifi√©e
                stored_page = pages_snapshot[page_id]
                # Comparaison par hash pour d√©tecter tout changement
                if current_hash != stored_page['hash']:
                    updated_pages.append({
                        'id': page_id,
                        'title': page.get('title', 'Sans titre'),
                        'url': page.get('url'),
                        'icon': page.get('icon'),
                        'changes': _detect_changes(stored_page, page)
                    })
                    has_updates = True
        # 2. V√©rifier les pages supprim√©es
        for page_id in pages_snapshot:
            if page_id not in current_pages_dict:
                deleted_page = pages_snapshot[page_id]
                deleted_pages.append({
                    'id': page_id,
                    'title': deleted_page.get('title', 'Sans titre')
                })
                has_updates = True
        # 3. V√©rifier les changements dans la file d'attente
        changes_in_queue = []
        while not changes_queue.empty():
            try:
                change = changes_queue.get_nowait()
                changes_in_queue.append(change)
                # Marquer comme ayant des updates si c'est r√©cent
                if change.get('timestamp', 0) > (last_check_timestamp or 0):
                    has_updates = True
            except:
                break
        # Remettre les changements dans la queue pour d'autres consommateurs
        for change in changes_in_queue:
            changes_queue.put(change)
        # 4. Mettre √† jour le snapshot
        pages_snapshot = {page['id']: {
            'last_edited': page.get('last_edited_time'),
            'title': page.get('title'),
            'hash': _generate_page_hash(page)
        } for page in current_pages}
        # 5. Mettre √† jour l'historique
        if has_updates:
            update_entry = {
                'timestamp': time.time(),
                'new_pages': len(new_pages),
                'updated_pages': len(updated_pages),
                'deleted_pages': len(deleted_pages)
            }
            update_history.append(update_entry)
            # Garder seulement les 100 derni√®res entr√©es
            if len(update_history) > 100:
                update_history.pop(0)
        # 6. Statistiques suppl√©mentaires
        time_since_last_check = time.time() - (last_check_timestamp or time.time())
        last_check_timestamp = time.time()
        # 7. Notification Push (si configur√©)
        socketio_instance = getattr(current_app, 'socketio', None)
        if has_updates and socketio_instance is not None:
            # √âmettre un √©v√©nement WebSocket
            socketio_instance.emit('pages_updated', {
                'new': new_pages,
                'updated': updated_pages,
                'deleted': deleted_pages
            })
        return jsonify({
            "has_updates": has_updates,
            "timestamp": time.time(),
            "time_since_last_check": time_since_last_check,
            "summary": {
                "new_pages": len(new_pages),
                "updated_pages": len(updated_pages),
                "deleted_pages": len(deleted_pages),
                "total_changes": len(new_pages) + len(updated_pages) + len(deleted_pages)
            },
            "details": {
                "new": new_pages[:10],
                "updated": updated_pages[:10],
                "deleted": deleted_pages[:10]
            },
            "stats": {
                "total_pages": len(current_pages),
                "last_update": max([p.get('last_edited_time', '') for p in current_pages]) if current_pages else None,
                "cache_age": cache_data.get('timestamp', 0)
            }
        })
    except Exception as e:
        print(f"‚ùå Erreur check updates: {e}")
        return jsonify({
            "has_updates": False,
            "error": str(e)
        }), 500

def _generate_page_hash(page):
    """G√©n√®re un hash unique pour une page bas√© sur ses propri√©t√©s importantes."""
    # Propri√©t√©s √† surveiller pour les changements
    relevant_props = {
        'title': page.get('title', ''),
        'last_edited_time': page.get('last_edited_time', ''),
        'icon': str(page.get('icon', '')),
        'cover': str(page.get('cover', '')),
        'parent': str(page.get('parent', '')),
        'archived': page.get('archived', False)
    }
    # Cr√©er une cha√Æne JSON tri√©e pour un hash coh√©rent
    content = json.dumps(relevant_props, sort_keys=True)
    # G√©n√©rer le hash SHA256
    return hashlib.sha256(content.encode()).hexdigest()

def _detect_changes(old_page, new_page):
    """D√©tecte quels champs ont chang√© entre deux versions d'une page."""
    changes = []
    # Titre
    if old_page.get('title') != new_page.get('title'):
        changes.append({
            'field': 'title',
            'old': old_page.get('title'),
            'new': new_page.get('title')
        })
    # Derni√®re modification
    old_time = old_page.get('last_edited')
    new_time = new_page.get('last_edited_time')
    if old_time != new_time:
        changes.append({
            'field': 'last_edited',
            'old': old_time,
            'new': new_time
        })
    # Ic√¥ne
    if str(old_page.get('icon')) != str(new_page.get('icon')):
        changes.append({'field': 'icon', 'changed': True})
    # Parent (d√©placement de page)
    if str(old_page.get('parent')) != str(new_page.get('parent')):
        changes.append({'field': 'parent', 'changed': True})
    return changes

@app.route('/api/pages/force_check', methods=['POST'])
def force_check_updates():
    """Force une v√©rification imm√©diate des mises √† jour."""
    global pages_snapshot, last_check_timestamp
    try:
        # R√©initialiser le snapshot pour forcer une comparaison compl√®te
        old_snapshot = pages_snapshot.copy()
        pages_snapshot = {}
        # Faire la v√©rification
        result = check_updates()
        # R√©cup√©rer la vraie r√©ponse Flask et le code
        if isinstance(result, tuple):
            response, status = result
        else:
            response = result
            status = 200
        # Extraire le JSON de la r√©ponse
        data = response.get_json(force=True)
        # Si pas de changements, restaurer l'ancien snapshot
        if not data.get('has_updates'):
            pages_snapshot = old_snapshot
        return response, status
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/pages/update_history')
def get_update_history():
    """Retourne l'historique des mises √† jour."""
    return jsonify({
        "history": update_history[-20:],
        "total_updates": len(update_history)
    })

def cleanup_update_tracking():
    """Nettoie les donn√©es de suivi trop anciennes."""
    global update_history
    # Garder seulement les updates des 24 derni√®res heures
    cutoff_time = time.time() - (24 * 60 * 60)
    update_history = [u for u in update_history if u['timestamp'] > cutoff_time]

def schedule_cleanup():
    while True:
        time.sleep(3600)  # Toutes les heures
        cleanup_update_tracking()

if __name__ == '__main__':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    
    print("üöÄ Notion Clipper Pro - Version 100% Locale")
    print("==========================================")
    load_configuration()
    
    print("\n‚ú® Fonctionnalit√©s:")
    print("  ‚úÖ Smart Polling (d√©tection intelligente des changements)")
    print("  ‚úÖ Cache local optimis√© (pas d'appels API inutiles)")
    print("  ‚úÖ Server-Sent Events pour mises √† jour temps r√©el")
    print("  ‚úÖ 100% local, aucun service externe requis")
    print("  ‚úÖ Gratuit et open source")
    
    print(f"\nüìä Configuration:")
    print(f"  ‚Ä¢ Check rapide: toutes les 30 secondes")
    print(f"  ‚Ä¢ Sync compl√®te: toutes les 5 minutes")
    print(f"  ‚Ä¢ Cache max: 2000 pages")
    print(f"  ‚Ä¢ Token Notion: {'‚úì' if notion_token else '‚úó'}")
    print(f"  ‚Ä¢ ImgBB: {'‚úì' if imgbb_key else '‚úó (images en texte)'}")
    
    print("\nüîó Endpoints:")
    print("  GET  /api/pages - Pages depuis le cache")
    print("  GET  /api/pages/changes - Changements r√©cents")
    print("  GET  /api/events/stream - SSE pour temps r√©el")
    print("  GET  /api/health - √âtat et statistiques")
    
    print("\nüí° Le syst√®me d√©tecte automatiquement les changements")
    print("   sans surcharger l'API Notion !")
    
    app.run(host='127.0.0.1', port=5000, debug=False, threaded=True)